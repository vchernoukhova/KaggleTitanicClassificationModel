{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import scipy.stats as st\n",
    "import scipy.special as spec\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit,StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import nbimporter\n",
    "from libraries_setup import AllLibraries\n",
    "from setup_code import *\n",
    "\n",
    "AllLibraries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "scoring = pd.read_csv('test.csv')\n",
    "\n",
    "full_data = [data, scoring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('PassengerId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.loc[:,'Survived']\n",
    "X = data.drop ('Survived', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "1                  S  \n",
       "2                  C  \n",
       "3                  S  \n",
       "4                  S  \n",
       "5                  S  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = 1992\n",
    "test_prc = 0.2\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split( X, y, test_size = test_prc, random_state = random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = X_train\n",
    "data_train['Survived'] = y_train\n",
    "\n",
    "data_test = X_test\n",
    "data_test['Survived'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert, Mrs. Edward Scott (Elisabeth Walton Mc...</td>\n",
       "      <td>female</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B3</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>2</td>\n",
       "      <td>Mallet, Master. Andre</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>S.C./PARIS 2079</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>371110</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Johan Birger</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3101277</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "780               1  Robert, Mrs. Edward Scott (Elisabeth Walton Mc...   \n",
       "828               2                              Mallet, Master. Andre   \n",
       "887               2                              Montvila, Rev. Juozas   \n",
       "110               3                                Moran, Miss. Bertha   \n",
       "393               3                       Gustafsson, Mr. Johan Birger   \n",
       "\n",
       "                Sex   Age  SibSp  Parch           Ticket      Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "780          female  43.0      0      1            24160  211.3375    B3   \n",
       "828            male   1.0      0      2  S.C./PARIS 2079   37.0042   NaN   \n",
       "887            male  27.0      0      0           211536   13.0000   NaN   \n",
       "110          female   NaN      1      0           371110   24.1500   NaN   \n",
       "393            male  28.0      2      0          3101277    7.9250   NaN   \n",
       "\n",
       "            Embarked  Survived  \n",
       "PassengerId                     \n",
       "780                S         1  \n",
       "828                C         1  \n",
       "887                S         0  \n",
       "110                Q         1  \n",
       "393                S         0  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, calibration = train_test_split(data_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the dataset is  712\n",
      "==================================================\n",
      " \n",
      "Number of  Name  levels:  712\n",
      "Number of  Sex  levels:  2\n",
      "Number of  Ticket  levels:  564\n",
      "Number of  Cabin  levels:  130\n",
      "Number of  Embarked  levels:  3\n",
      "Number of  Title  levels:  7\n",
      "Number of  Last_name  levels:  558\n",
      "Number of  Other_full_name  levels:  119\n",
      "Number of  Other_last_name  levels:  117\n",
      "Number of  Cabin_letter  levels:  7\n",
      "Number of  Ticket_first  levels:  37\n",
      "Number of  Ticket_second  levels:  554\n"
     ]
    }
   ],
   "source": [
    "#ShowTypes(data_train)\n",
    "ShowLevels(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### FEATURE ENGINEERING ####################\n",
    "create_new_var (data_train)\n",
    "\n",
    "#Embarked\n",
    "data_train = impute_most_frequent (data_train, 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = impact_coding(data_train,data_train, 'Embarked', 'Embarked_impact')\n",
    "[data_train, log_cabin] = impact_coding(data_train, 'Cabin', 'Cabin_impact')\n",
    "[data_train, log_ticket] = impact_coding(data_train, 'Ticket', 'Ticket_impact')\n",
    "[data_train, log_last_name] = impact_coding(data_train, 'Last_name', 'Last_name_impact')\n",
    "[data_train, log_other_last_name] = impact_coding(data_train, 'Other_last_name', 'Other_last_name_impact')\n",
    "\n",
    "[data_train, log_ticket_first] = impact_coding(data_train, 'Ticket_first', 'Ticket_first_impact')\n",
    "[data_train, log_ticket_second] = impact_coding(data_train, 'Ticket_second', 'Ticket_second_impact')\n",
    "\n",
    "data_train = change_var_types (data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "add_missing_ind(data_train, 'Age', 'MisAge')\n",
    "data_train = impute_regressor(data_train, 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.drop ('Name', 1) # 1 for columns, 0 for rows\n",
    "data_train = data_train.drop ('Ticket', 1)\n",
    "data_train = data_train.drop ('Cabin', 1) \n",
    "\n",
    "data_train = data_train.drop ('Last_name', 1) \n",
    "data_train = data_train.drop ('Other_full_name', 1) \n",
    "data_train = data_train.drop ('Other_last_name', 1) \n",
    "data_train = data_train.drop ('Ticket_first', 1) \n",
    "data_train = data_train.drop ('Ticket_second', 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = create_dummies(data_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### FEATURE ENGINEERING FOR TESTING ####################\n",
    "\n",
    "create_new_var (data_test)\n",
    "\n",
    "#Embarked\n",
    "data_test = impute_most_frequent (data_test, 'Embarked')\n",
    "\n",
    "data_test = pd.merge(data_test, log_cabin,  on='Cabin', how = 'left')\n",
    "data_test['Cabin_impact'] = data_test['Cabin_impact'].fillna(0)\n",
    "\n",
    "data_test = pd.merge(data_test, log_ticket,  on='Ticket', how = 'left')\n",
    "data_test['Ticket_impact'] = data_test['Ticket_impact'].fillna(0)\n",
    "\n",
    "data_test = pd.merge(data_test, log_last_name,  on='Last_name', how = 'left')\n",
    "data_test['Last_name_impact'] = data_test['Last_name_impact'].fillna(0)\n",
    "\n",
    "data_test = pd.merge(data_test, log_other_last_name,  on='Other_last_name', how = 'left')\n",
    "data_test['Other_last_name_impact'] = data_test['Other_last_name_impact'].fillna(0)\n",
    "\n",
    "data_test = pd.merge(data_test, log_ticket_first,  on='Ticket_first', how = 'left')\n",
    "data_test['Ticket_first_impact'] = data_test['Ticket_first_impact'].fillna(0)\n",
    "\n",
    "data_test = pd.merge(data_test, log_ticket_second,  on='Ticket_second', how = 'left')\n",
    "data_test['Ticket_second_impact'] = data_test['Ticket_second_impact'].fillna(0)\n",
    "\n",
    "data_test = change_var_types (data_test)\n",
    "\n",
    "#Age\n",
    "add_missing_ind(data_test, 'Age', 'MisAge')\n",
    "impute_regressor(data_test, 'Age')\n",
    "\n",
    "data_test = data_test.drop ('Name', 1) # 1 for columns, 0 for rows\n",
    "data_test = data_test.drop ('Ticket', 1)\n",
    "data_test = data_test.drop ('Cabin', 1) \n",
    "\n",
    "data_test = data_test.drop ('Last_name', 1) \n",
    "data_test = data_test.drop ('Other_full_name', 1) \n",
    "data_test = data_test.drop ('Other_last_name', 1) \n",
    "data_test = data_test.drop ('Ticket_first', 1) \n",
    "data_test = data_test.drop ('Ticket_second', 1) \n",
    "\n",
    "data_test = create_dummies(data_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Categorical variables of the dataset are: \n",
      "\u001b[0m\n",
      "\n",
      " \n",
      "\u001b[1m Numerical variables of the dataset are: \n",
      "\u001b[0m\n",
      "Age\n",
      "Fare\n",
      "Survived\n",
      "Cabin_impact\n",
      "Ticket_impact\n",
      "Last_name_impact\n",
      "Other_last_name_impact\n",
      "Ticket_first_impact\n",
      "Ticket_second_impact\n"
     ]
    }
   ],
   "source": [
    "#ShowTypes(data_train)\n",
    "#data_train.isna().sum()\n",
    "#ShowLevels(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train.loc[:,'Survived']\n",
    "X_train = data_train.drop ('Survived', 1)\n",
    "\n",
    "y_test = data_test.loc[:,'Survived']\n",
    "X_test = data_test.drop ('Survived', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_impact</th>\n",
       "      <th>Ticket_impact</th>\n",
       "      <th>Last_name_impact</th>\n",
       "      <th>Other_last_name_impact</th>\n",
       "      <th>Ticket_first_impact</th>\n",
       "      <th>Ticket_second_impact</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Cabin_letter_A</th>\n",
       "      <th>Cabin_letter_B</th>\n",
       "      <th>Cabin_letter_C</th>\n",
       "      <th>Cabin_letter_D</th>\n",
       "      <th>Cabin_letter_E</th>\n",
       "      <th>Cabin_letter_G</th>\n",
       "      <th>Cabin_letter_T</th>\n",
       "      <th>MisAge_0.0</th>\n",
       "      <th>MisAge_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.5</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.464012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.5</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>19.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  Cabin_impact  Ticket_impact  Last_name_impact  \\\n",
       "0  19.0   6.7500           0.0       0.000000          0.000000   \n",
       "1  70.5   7.7500           0.0       0.000000          0.000000   \n",
       "2  37.0   7.9250           0.0       0.000000         -9.464012   \n",
       "3  32.5  27.7208           0.0       0.000000          0.000000   \n",
       "4  13.0  19.5000           0.0       9.649966          9.649966   \n",
       "\n",
       "   Other_last_name_impact  Ticket_first_impact  Ticket_second_impact  \\\n",
       "0                     0.0             0.000000              0.000000   \n",
       "1                     0.0             0.000000              0.000000   \n",
       "2                     0.0             0.000000              0.000000   \n",
       "3                     0.0             1.104499              0.000000   \n",
       "4                     0.0             0.000000              9.649966   \n",
       "\n",
       "   Pclass_1  Pclass_2     ...      Title_Rev  Cabin_letter_A  Cabin_letter_B  \\\n",
       "0         0         0     ...              0               0               0   \n",
       "1         0         0     ...              0               0               0   \n",
       "2         0         0     ...              0               0               0   \n",
       "3         1         0     ...              0               0               0   \n",
       "4         0         1     ...              0               0               0   \n",
       "\n",
       "   Cabin_letter_C  Cabin_letter_D  Cabin_letter_E  Cabin_letter_G  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   Cabin_letter_T  MisAge_0.0  MisAge_1.0  \n",
       "0               0           1           0  \n",
       "1               0           1           0  \n",
       "2               0           1           0  \n",
       "3               0           0           1  \n",
       "4               0           1           0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time Was:  162.45745992660522 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=37, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=11,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1219, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ TUNNING RANDOM FOREST ########################################\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "#rf.get_params()\n",
    "\n",
    "row_num = X_train.shape[0]\n",
    "\n",
    "n_estimators_start = 200\n",
    "n_estimators_end =  2000\n",
    "\n",
    "max_depth_start = 10\n",
    "max_depth_end = 110\n",
    "\n",
    "min_samples_split_start =  round(0.01*row_num) #2\n",
    "min_samples_split_end = round(0.03*row_num) #10\n",
    "\n",
    "min_samples_leaf_start = 1\n",
    "min_samples_leaf_end = 20 #4\n",
    "\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': st.randint (n_estimators_start, n_estimators_end),\n",
    "               'max_depth': st.randint (max_depth_start, max_depth_end),\n",
    "               'min_samples_split': st.randint (min_samples_split_start, min_samples_split_end),\n",
    "               'min_samples_leaf': st.randint (min_samples_leaf_start, min_samples_leaf_end),\n",
    "               'max_features': max_features,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                                           param_distributions = random_grid, \n",
    "                                           n_iter = 100, cv = 5, scoring = 'roc_auc', verbose=False, \n",
    "                                           random_state=42, n_jobs = -1)\n",
    "\n",
    "start = time.time()\n",
    "rf_random.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "RandomForestClassifierTuned = RandomForestClassifier()\n",
    "RandomForestClassifierTuned.set_params(**rf_random.best_params_)\n",
    "\n",
    "##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time Was:  6.960388898849487 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.2759395304685146,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 8,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 30,\n",
       " 'presort': 'auto',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ TUNNING GRADIENT BOOSTING ########################################\n",
    "\n",
    "#best model (roc = 82.727483): with n_est 3 - 40; max_depth 3-40; learning rate 0.05 - 0.4\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "# consider using GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "#rf.get_params()\n",
    "\n",
    "row_num = X_train.shape[0]\n",
    "\n",
    "learning_rate_start = 0.09 #0.03\n",
    "learning_rate_end = 0.2 #0.3\n",
    "\n",
    "n_estimators_start = 3\n",
    "n_estimators_end =  40 #80\n",
    "\n",
    "max_depth_start = 3\n",
    "max_depth_end = 40 #20\n",
    "\n",
    "min_samples_split_start = round(0.01*row_num)\n",
    "min_samples_split_end = round(0.03*row_num)\n",
    "\n",
    "min_samples_leaf_start = 1\n",
    "min_samples_leaf_end = 20 \n",
    "\n",
    "\n",
    "random_grid = {  \n",
    "                \"learning_rate\": st.uniform (learning_rate_start, learning_rate_end),\n",
    "                \"n_estimators\": st.randint (n_estimators_start, n_estimators_end),\n",
    "                \"max_depth\": st.randint (max_depth_start, max_depth_end)\n",
    "            }\n",
    "\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "gb_random = RandomizedSearchCV(estimator = gb, \n",
    "                                           param_distributions = random_grid, \n",
    "                                           n_iter = 100, cv = 10, scoring = 'roc_auc', verbose=False, \n",
    "                                           random_state=42, n_jobs = -1)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "gb_random.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "GradientBoostingClassifierTuned = GradientBoostingClassifier()\n",
    "GradientBoostingClassifierTuned.set_params(**gb_random.best_params_)\n",
    "GradientBoostingClassifierTuned.get_params()\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time Was:  6.82409405708313 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.9759664405348728,\n",
       " 'gamma': 7.709113770642705,\n",
       " 'learning_rate': 0.21881442382027494,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 9.093085252463617,\n",
       " 'missing': None,\n",
       " 'n_estimators': 67,\n",
       " 'n_jobs': 1,\n",
       " 'nthread': None,\n",
       " 'objective': 'binary:logistic',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 4.321413783592179,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': None,\n",
       " 'silent': True,\n",
       " 'subsample': 0.9697082498532124}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################ TUNNING XGBOOST ########################################\n",
    "\n",
    "#https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "# consider using GridSearchCV\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "#rf.get_params()\n",
    "\n",
    "row_num = X_train.shape[0]\n",
    "\n",
    "learning_rate_start = 0.05\n",
    "learning_rate_end = 0.4\n",
    "\n",
    "n_estimators_start = 3\n",
    "n_estimators_end =  80\n",
    "\n",
    "max_depth_start = 3\n",
    "max_depth_end = 50\n",
    "\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "random_grid = {  \n",
    "    \"n_estimators\": st.randint(n_estimators_start, n_estimators_end),\n",
    "    \"max_depth\": st.randint(max_depth_start, max_depth_end),\n",
    "    \"learning_rate\": st.uniform(learning_rate_start, learning_rate_end),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive\n",
    "}\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb, \n",
    "                                           param_distributions = random_grid, \n",
    "                                           n_iter = 100, cv = 10, scoring = 'roc_auc', verbose=False, \n",
    "                                           random_state=42, n_jobs = -1)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "xgb_random.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Execution Time Was: \", end - start, \"seconds\")\n",
    "\n",
    "XGBClassifierTuned = XGBClassifier()\n",
    "XGBClassifierTuned.set_params(**xgb_random.best_params_)\n",
    "XGBClassifierTuned.get_params()\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "  # SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "  #  GaussianNB(),\n",
    "  #  LinearDiscriminantAnalysis(),\n",
    "  #  QuadraticDiscriminantAnalysis(),\n",
    "    XGBClassifier(),\n",
    "    RandomForestClassifierTuned,\n",
    "    GradientBoostingClassifierTuned,\n",
    "    XGBClassifierTuned\n",
    "]\n",
    "\n",
    "names = [\n",
    "        'KNeighborsClassifier',\n",
    "   #     'Support Vector Machine',\n",
    "        'NuSVC',\n",
    "        'Decision Tree',\n",
    "        'Random Forest',\n",
    "        'AdaBoost',\n",
    "        'Gradient Boosting',\n",
    "   #     'Gaussian NB',\n",
    "   #     'Linear Discriminant Analysis',\n",
    "   #     'Quadratic Discriminant Analysis',\n",
    "        'XGBoost',\n",
    "        'Random Forest Tuned',\n",
    "        'Gradient Boosting Tuned',\n",
    "        'XGBoost Tuned'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folds = 10\n",
    "random = 23\n",
    "test_prc = 0.3\n",
    "\n",
    "#X_train , X_test, y_train, y_test = train_test_split( X, y, test_size = test_prc, random_state = random)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = folds, test_size=test_prc, random_state=random)\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = random)\n",
    "\n",
    "\n",
    "log_cols=[\"Index\", \"Classifier\", \"ROC\", \"Accuracy\", \"Log Loss\", 'Precision', 'Recall']\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "index = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    \n",
    "    index += 1\n",
    "    \n",
    "    X_train_kf, X_test_kf = X_train.values[train_index], X_train.values[test_index]\n",
    "    y_train_kf, y_test_kf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # FOR MORE METRICS SEE: http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "    for name, clf in zip(names,classifiers):\n",
    "\n",
    "        clf.fit(X_train_kf, y_train_kf)\n",
    "\n",
    "        y_pred_kf = clf.predict(X_test_kf)\n",
    "        y_pred_prob_kf = clf.predict_proba(X_test_kf)\n",
    "\n",
    "        #name = clf.__class__.__name__\n",
    "\n",
    "        roc = 100*roc_auc_score(y_test_kf, y_pred_kf)\n",
    "        acc = 100*accuracy_score(y_test_kf, y_pred_kf)\n",
    "        ll = log_loss(y_test_kf, y_pred_prob_kf)\n",
    "\n",
    "        prec = 100*precision_score(y_test_kf, y_pred_kf)\n",
    "        recall = 100*recall_score(y_test_kf, y_pred_kf)\n",
    "\n",
    "        log_entry = pd.DataFrame([[index, name, roc, acc, ll, prec, recall]], columns=log_cols)\n",
    "        log = log.append(log_entry)\n",
    "\n",
    "#log\n",
    "final_log = log.groupby(['Classifier'])[\"ROC\", \"Accuracy\", \"Log Loss\", 'Precision', 'Recall'].mean()\n",
    "final_log.sort_values(by = 'ROC', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>99.299305</td>\n",
       "      <td>99.301643</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>98.988506</td>\n",
       "      <td>99.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <td>99.069390</td>\n",
       "      <td>99.019953</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>98.286535</td>\n",
       "      <td>99.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>99.066747</td>\n",
       "      <td>99.019953</td>\n",
       "      <td>0.035348</td>\n",
       "      <td>98.263547</td>\n",
       "      <td>99.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>99.066747</td>\n",
       "      <td>99.019953</td>\n",
       "      <td>0.029970</td>\n",
       "      <td>98.263547</td>\n",
       "      <td>99.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>99.001812</td>\n",
       "      <td>99.017997</td>\n",
       "      <td>0.174245</td>\n",
       "      <td>98.608374</td>\n",
       "      <td>98.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Tuned</th>\n",
       "      <td>98.896481</td>\n",
       "      <td>98.736307</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>97.252053</td>\n",
       "      <td>99.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>98.825883</td>\n",
       "      <td>98.879108</td>\n",
       "      <td>0.387142</td>\n",
       "      <td>98.608374</td>\n",
       "      <td>98.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Tuned</th>\n",
       "      <td>98.709604</td>\n",
       "      <td>98.738263</td>\n",
       "      <td>0.078465</td>\n",
       "      <td>98.263547</td>\n",
       "      <td>98.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>97.010722</td>\n",
       "      <td>97.059859</td>\n",
       "      <td>0.334684</td>\n",
       "      <td>95.938964</td>\n",
       "      <td>96.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>94.801420</td>\n",
       "      <td>93.832048</td>\n",
       "      <td>0.111966</td>\n",
       "      <td>86.979412</td>\n",
       "      <td>99.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ROC   Accuracy  Log Loss  Precision     Recall\n",
       "Classifier                                                                   \n",
       "Random Forest            99.299305  99.301643  0.040318  98.988506  99.285714\n",
       "Random Forest Tuned      99.069390  99.019953  0.046401  98.286535  99.285714\n",
       "Gradient Boosting        99.066747  99.019953  0.035348  98.263547  99.285714\n",
       "XGBoost                  99.066747  99.019953  0.029970  98.263547  99.285714\n",
       "AdaBoost                 99.001812  99.017997  0.174245  98.608374  98.928571\n",
       "XGBoost Tuned            98.896481  98.736307  0.090939  97.252053  99.642857\n",
       "Decision Tree            98.825883  98.879108  0.387142  98.608374  98.571429\n",
       "Gradient Boosting Tuned  98.709604  98.738263  0.078465  98.263547  98.571429\n",
       "KNeighborsClassifier     97.010722  97.059859  0.334684  95.938964  96.785714\n",
       "NuSVC                    94.801420  93.832048  0.111966  86.979412  99.285714"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'presort': 'auto',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.24965903579335505,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'presort': 'auto',\n",
       " 'random_state': None,\n",
       " 'subsample': 1.0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifierTuned.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.3296089385475"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running on the whole dataset\n",
    "best_classifier = RandomForestClassifier() #GradientBoostingClassifierTuned\n",
    "best_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "y_pred_prob = best_classifier.predict_proba(X_test)\n",
    "\n",
    "#X_test['Survived_pred'] = y_pred\n",
    "acc = 100*accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = pd.read_csv('test.csv')\n",
    "\n",
    "scoring.set_index('PassengerId', inplace=True)\n",
    "\n",
    "create_new_var (scoring)\n",
    "\n",
    "#Embarked\n",
    "scoring = impute_most_frequent (scoring, 'Embarked')\n",
    "\n",
    "scoring = scoring.reset_index().merge(log_cabin, on='Cabin', how = 'left').set_index('PassengerId')\n",
    "scoring['Cabin_impact'] = scoring['Cabin_impact'].fillna(0)\n",
    "\n",
    "scoring = scoring.reset_index().merge(log_ticket, on='Ticket', how = 'left').set_index('PassengerId')\n",
    "scoring['Ticket_impact'] = scoring['Ticket_impact'].fillna(0)\n",
    "\n",
    "scoring = scoring.reset_index().merge( log_last_name,  on='Last_name', how = 'left').set_index('PassengerId')\n",
    "scoring['Last_name_impact'] = scoring['Last_name_impact'].fillna(0)\n",
    "\n",
    "scoring = scoring.reset_index().merge(log_other_last_name,  on='Other_last_name', how = 'left').set_index('PassengerId')\n",
    "scoring['Other_last_name_impact'] = scoring['Other_last_name_impact'].fillna(0)\n",
    "\n",
    "scoring = scoring.reset_index().merge( log_ticket_first,  on='Ticket_first', how = 'left').set_index('PassengerId')\n",
    "scoring['Ticket_first_impact'] = scoring['Ticket_first_impact'].fillna(0)\n",
    "\n",
    "scoring = scoring.reset_index().merge( log_ticket_second,  on='Ticket_second', how = 'left').set_index('PassengerId')\n",
    "scoring['Ticket_second_impact'] = scoring['Ticket_second_impact'].fillna(0)\n",
    "\n",
    "scoring = change_var_types (scoring)\n",
    "\n",
    "#Age\n",
    "add_missing_ind(scoring, 'Age', 'MisAge')\n",
    "impute_regressor(scoring, 'Age')\n",
    "impute_regressor(scoring, 'Fare')\n",
    "\n",
    "scoring = scoring.drop ('Name', 1) # 1 for columns, 0 for rows\n",
    "scoring = scoring.drop ('Ticket', 1)\n",
    "scoring = scoring.drop ('Cabin', 1) \n",
    "\n",
    "\n",
    "scoring = scoring.drop ('Last_name', 1) \n",
    "scoring = scoring.drop ('Other_full_name', 1) \n",
    "scoring = scoring.drop ('Other_last_name', 1) \n",
    "scoring = scoring.drop ('Ticket_first', 1) \n",
    "scoring = scoring.drop ('Ticket_second', 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = create_dummies(scoring,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on the whole dataset\n",
    "y = pd.concat([y_train, y_test])\n",
    "X = pd.concat([X_train, X_test])\n",
    "\n",
    "X_scoring = scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.isna().sum()\n",
    "X['Cabin_letter_T'] = X['Cabin_letter_T'].fillna(0)\n",
    "X['Cabin_letter_F'] = X['Cabin_letter_F'].fillna(0)\n",
    "\n",
    "X_scoring['Cabin_letter_F'] = X_scoring['Cabin_letter_F'].fillna(0)\n",
    "X_scoring['Cabin_letter_T'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_impact</th>\n",
       "      <th>Ticket_impact</th>\n",
       "      <th>Last_name_impact</th>\n",
       "      <th>Other_last_name_impact</th>\n",
       "      <th>Ticket_first_impact</th>\n",
       "      <th>Ticket_second_impact</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_letter_A</th>\n",
       "      <th>Cabin_letter_B</th>\n",
       "      <th>Cabin_letter_C</th>\n",
       "      <th>Cabin_letter_D</th>\n",
       "      <th>Cabin_letter_E</th>\n",
       "      <th>Cabin_letter_F</th>\n",
       "      <th>Cabin_letter_G</th>\n",
       "      <th>MisAge_0.0</th>\n",
       "      <th>MisAge_1.0</th>\n",
       "      <th>Cabin_letter_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.132623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.649966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age     Fare  Cabin_impact  Ticket_impact  Last_name_impact  \\\n",
       "PassengerId                                                                 \n",
       "892          34.5   7.8292           0.0       0.000000          1.132623   \n",
       "893          47.0   7.0000           0.0       0.000000          0.000000   \n",
       "894          62.0   9.6875           0.0       0.000000          0.000000   \n",
       "895          27.0   8.6625           0.0       0.000000          0.000000   \n",
       "896          22.0  12.2875           0.0       9.649966          9.649966   \n",
       "\n",
       "             Other_last_name_impact  Ticket_first_impact  \\\n",
       "PassengerId                                                \n",
       "892                        0.000000                  0.0   \n",
       "893                        9.649966                  0.0   \n",
       "894                        0.000000                  0.0   \n",
       "895                        0.000000                  0.0   \n",
       "896                        0.000000                  0.0   \n",
       "\n",
       "             Ticket_second_impact  Pclass_1  Pclass_2       ...        \\\n",
       "PassengerId                                                 ...         \n",
       "892                      0.000000         0         0       ...         \n",
       "893                      0.000000         0         0       ...         \n",
       "894                      0.000000         0         1       ...         \n",
       "895                      0.000000         0         0       ...         \n",
       "896                      9.649966         0         0       ...         \n",
       "\n",
       "             Cabin_letter_A  Cabin_letter_B  Cabin_letter_C  Cabin_letter_D  \\\n",
       "PassengerId                                                                   \n",
       "892                       0               0               0               0   \n",
       "893                       0               0               0               0   \n",
       "894                       0               0               0               0   \n",
       "895                       0               0               0               0   \n",
       "896                       0               0               0               0   \n",
       "\n",
       "             Cabin_letter_E  Cabin_letter_F  Cabin_letter_G  MisAge_0.0  \\\n",
       "PassengerId                                                               \n",
       "892                       0               0               0           1   \n",
       "893                       0               0               0           1   \n",
       "894                       0               0               0           1   \n",
       "895                       0               0               0           1   \n",
       "896                       0               0               0           1   \n",
       "\n",
       "             MisAge_1.0  Cabin_letter_T  \n",
       "PassengerId                              \n",
       "892                   0               0  \n",
       "893                   0               0  \n",
       "894                   0               0  \n",
       "895                   0               0  \n",
       "896                   0               0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scoring.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = RandomForestClassifier() \n",
    "best_classifier.fit(X, y)\n",
    "\n",
    "y_pred = best_classifier.predict(X_scoring)\n",
    "#y_pred_prob = best_classifier.predict_proba(X_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scoring['Survived'] = y_pred\n",
    "\n",
    "submission = X_scoring[['Survived']]\n",
    "submission.reset_index(inplace=True)\n",
    "submission.to_csv('submission.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         1\n",
       "1          893         0\n",
       "2          894         1\n",
       "3          895         1\n",
       "4          896         0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
